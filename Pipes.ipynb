{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d766cf",
   "metadata": {},
   "source": [
    "Import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd66232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, RobustScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from tanzania import extend_train_test_with_countries, save_png, Colors\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::ConvergenceWarning,ignore::UserWarning\"\n",
    "\n",
    "Colors.init_colors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27b429",
   "metadata": {},
   "source": [
    "Define new transformer, which can add a new feature as a sum of others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSumFeature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_src: tuple, col_tgt: str):\n",
    "        self.col_src = col_src\n",
    "        self.col_tgt = col_tgt\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        X[self.col_tgt] = X[self.col_src].sum(axis = 1)\n",
    "        return X\n",
    "\n",
    "    def set_output(self, transform: str = None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819e9e2",
   "metadata": {},
   "source": [
    "Get data with country data columns attached. Drop 'ID' column, as it is not imortant for model training. extract y to mak etrain-test split possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbacbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extend_train_test_with_countries(pd.read_csv('data/Train.csv'))\n",
    "X.drop('ID', axis = 1, inplace = True)\n",
    "\n",
    "y = X.pop('total_cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5ec46",
   "metadata": {},
   "source": [
    "split train-test. merge train X and y together to make them sync, when some rows will be dropped. there are very small amount of missed travel_with values, which can't be predicted by total_male + total_female = 1, drop those rows, same as rows, where total_male or total_female = np.nan. they are less than 1%\n",
    "\n",
    "everything I should change in test data should be done using pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size= 0.75)\n",
    "\n",
    "X_train = X_train.join(y_train)\n",
    "# drop all the rows from dataset, wehere 'travel_with' = np.nan and total_male + total_female != 1. 20 items\n",
    "mask = X_train['travel_with'].isna() & ((X_train['total_male'] + X_train['total_female']) != 1)\n",
    "print(f'from {X_train.shape[0]} will remove {mask.sum()} because \"travel_with\" is unknown and number of tourists not 1')\n",
    "\n",
    "X_train = X_train.drop(X_train[mask].index)\n",
    "\n",
    "print(f'{X_train.shape[0]} rows left')\n",
    "\n",
    "# drop all the rows, where total_male or total_female = np.nan\n",
    "X_train = X_train.dropna(subset=['total_male', 'total_female'])\n",
    "print(f'after not defined total_male and total_female {X_train.shape[0]} rows left')\n",
    "\n",
    "y_train = X_train.pop('total_cost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ce9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [ col for col in X_train.columns if (X_train[col].dtype == 'int') or (X_train[col].dtype == 'float') ]\n",
    "cat_cols = [ col for col in X_train.columns if X_train[col].dtype == 'object' ]\n",
    "print(f'Numerical: {len(num_cols)}, Categorical: {len(cat_cols)}, Initially: {len(X_train.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112e5bb",
   "metadata": {},
   "source": [
    "As I already removed all the rows, where 'travel_width' is missed and can't be assigned as alone, I can use any of the following methods:\n",
    "\n",
    "* Use SimpleImputer for one column Зшзу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline_most_impressing = Pipeline([\n",
    "    ('value_impress', SimpleImputer(strategy='constant', fill_value = 'No comments')),\n",
    "    ('onehot_impress', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "pipeline_travel_with = Pipeline([\n",
    "    ('value_travel', SimpleImputer(strategy='constant', fill_value = 'Alone')),\n",
    "    ('onehot_travel', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "pipeline_cat_other = Pipeline([\n",
    "    ('imput_cats', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot_other', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "pipeline_numeric = Pipeline([\n",
    "    ('imput_num', SimpleImputer(strategy='most_frequent').set_output(transform=\"pandas\")),\n",
    "    ('add_nights', Pipeline([\n",
    "        ('nights', AddSumFeature(['night_mainland', 'night_zanzibar'], 'nights'))\n",
    "        ])\n",
    "    ),\n",
    "    ('add_people', Pipeline([\n",
    "        ('people', AddSumFeature(['total_male', 'total_female'], 'people'))\n",
    "        ])\n",
    "    ),\n",
    "    ('scale_num', StandardScaler())\n",
    "])\n",
    "\n",
    "process_columns = ColumnTransformer([\n",
    "    ('impressing', pipeline_most_impressing, ['most_impressing']),\n",
    "    ('with', pipeline_travel_with, ['travel_with']),\n",
    "    ('cats', pipeline_cat_other, [col for col in cat_cols if col not in ['most_impressing', 'travel_with']]),\n",
    "    ('nums', pipeline_numeric, num_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_report(name: str, y_test: pd.DataFrame, y_pred: pd.DataFrame):\n",
    "    print(f'{name} model:')\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    rmse_test = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "    print(f'RMSE = {rmse_test.round(3)}, R2_score = {r2_test.round(5)}')\n",
    "\n",
    "    # make a graph\n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    df_test = pd.DataFrame({\n",
    "        'real': y_test,\n",
    "        'predicted': y_pred,\n",
    "        'residuals': residuals\n",
    "    })\n",
    "\n",
    "    sns.scatterplot(data = df_test, y = 'residuals', x = 'predicted', color = Colors.dark_matcha_green)\n",
    "    plt.axhline(0, color = Colors.accent_4, linestyle='--', linewidth = 3)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Residual')\n",
    "    plt.title('Pipeline residuals plot')\n",
    "\n",
    "    save_png(f'pics/{name}_model_performance.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('prep', process_columns),\n",
    "    ('model', KNeighborsRegressor(n_neighbors = 15, p=1, metric = 'minkowski', weights = 'uniform'))\n",
    "])\n",
    "\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred = knn_pipe.predict(X_test)\n",
    "\n",
    "create_model_report('Linear Regression', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45cf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('Linear Regressor', LinearRegression(), {}),\n",
    "    ('Elastic Net', ElasticNet(), {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "        'l1_ratio': [0.1, 0.5, 0.7, 0.9, 1]\n",
    "        }),\n",
    "    ('KNeighborsRegressor', KNeighborsRegressor(n_jobs = -1), {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2, 3]\n",
    "    }),\n",
    "    ('Decision Tree Regressor', DecisionTreeRegressor(max_features = 'sqrt'), {\n",
    "        'max_depth': [2, 5, 10, 15, 20],\n",
    "        'min_samples_split': range(2, 5),\n",
    "        'min_samples_leaf': [1, 2]}),\n",
    "    ('Random Forest Regressor', RandomForestRegressor(n_jobs = -1), {\n",
    "        'max_depth': [2, 5, 10, 15, 20],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "        'n_estimators': [50, 70, 90, 110, 150, 200],\n",
    "        'bootstrap': [True, False]}),\n",
    "    ('Ada Boost Regressor', AdaBoostRegressor(), {\n",
    "        'n_estimators': [50, 70, 90, 110, 150, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "        'loss': ['linear', 'square', 'exponential']}),\n",
    "    ('Gradient Boosting Regressor', GradientBoostingRegressor(), {\n",
    "        'n_estimators': [50, 70, 90, 110, 150, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'max_depth': [2, 3, 4, 5],\n",
    "        'max_features': [None, 'sqrt', 'log2']}),\n",
    "    ('SGD Regressor', SGDRegressor(max_iter = 5000), {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'l1_ratio': [0.1, 0.5, 0.9],\n",
    "    })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352096ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, est, params in estimators:\n",
    "    y_pred_check = y_test\n",
    "    \n",
    "    if len(params) == 0:\n",
    "        ppline = Pipeline([\n",
    "            ('prep', process_columns),\n",
    "            ('model', est)\n",
    "        ])\n",
    "        ppline.fit(X_train, y_train)\n",
    "        y_pred_check = ppline.predict(X_test)\n",
    "\n",
    "        results.append([\n",
    "            name, \n",
    "            r2_score(y_test, y_pred_check).round(4),\n",
    "            (mean_squared_error(y_test, y_pred_check) ** 0.5).round(2),\n",
    "            {}])\n",
    "    else:\n",
    "        ppline = Pipeline([\n",
    "            ('prep', process_columns),\n",
    "            ('model', est)\n",
    "        ])\n",
    "\n",
    "        p_grid = {}\n",
    "        for key, val in params.items():\n",
    "            p_grid[f'model__{key}'] = val\n",
    "\n",
    "        gs = GridSearchCV(\n",
    "            estimator = ppline,\n",
    "            param_grid = p_grid,\n",
    "            n_jobs = -1,\n",
    "            cv = 5,\n",
    "            scoring = 'r2' #‘neg_root_mean_squared_error’\n",
    "        )\n",
    "\n",
    "        gs.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_check = gs.best_estimator_.predict(X_test)\n",
    "        results.append([\n",
    "            name, \n",
    "            r2_score(y_test, y_pred_check).round(4),\n",
    "            (mean_squared_error(y_test, y_pred_check) ** 0.5).round(2),\n",
    "            gs.best_params_])\n",
    "    \n",
    "    print(f'{name:35} R2: {r2_score(y_test, y_pred_check).round(4)}')\n",
    "\n",
    "print('===' * 30)\n",
    "for r in results:\n",
    "    print(f'{r[0]:35} R2: {r[1]}, RMSE: {r[2]}, best params: {r[3]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
